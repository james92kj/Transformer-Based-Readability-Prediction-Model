{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":25914,"databundleVersionId":2227051,"sourceType":"competition"}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"0d669167-96ad-44f2-a287-9abf1abb1996","_cell_guid":"eaa94786-b953-470b-a544-2e548176489c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-05T01:05:02.044921Z","iopub.execute_input":"2025-02-05T01:05:02.045198Z","iopub.status.idle":"2025-02-05T01:05:02.956000Z","shell.execute_reply.started":"2025-02-05T01:05:02.045163Z","shell.execute_reply":"2025-02-05T01:05:02.955038Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import (AutoTokenizer, AutoModel, \n                        AutoConfig, AutoModelForTokenClassification,\n                        AutoModelForSequenceClassification)\n\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\nfrom sklearn.model_selection import KFold\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\nfrom enum import Enum\nimport torch.nn as nn\nimport numpy as np\nimport pandas as pd\nimport random\nimport torch\nimport pickle\nimport os\nimport math\nimport re\nimport json\nimport gc\nimport time","metadata":{"_uuid":"0e5946b6-ba2d-4c65-9f59-cb5601b5a681","_cell_guid":"95a5f08c-db27-4e40-bb99-7ab7e7ee9a75","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-05T02:25:24.100577Z","iopub.execute_input":"2025-02-05T02:25:24.100898Z","iopub.status.idle":"2025-02-05T02:25:24.106116Z","shell.execute_reply.started":"2025-02-05T02:25:24.100871Z","shell.execute_reply":"2025-02-05T02:25:24.105219Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"0cb6ab01-a58d-4a3a-b429-336e1e6318db","_cell_guid":"bcdd6772-ca35-4631-a9bc-6f920a851aca","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-05T01:07:01.441767Z","iopub.execute_input":"2025-02-05T01:07:01.442316Z","iopub.status.idle":"2025-02-05T01:07:01.445878Z","shell.execute_reply.started":"2025-02-05T01:07:01.442284Z","shell.execute_reply":"2025-02-05T01:07:01.445094Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# utility for setting the seed \ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    return seed","metadata":{"_uuid":"e4a9f31a-211b-45ca-9cf0-511bbf8365e0","_cell_guid":"e8ba7eec-dd84-42cb-b54c-87d978168f99","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-05T01:07:02.634262Z","iopub.execute_input":"2025-02-05T01:07:02.634699Z","iopub.status.idle":"2025-02-05T01:07:02.640009Z","shell.execute_reply.started":"2025-02-05T01:07:02.634660Z","shell.execute_reply":"2025-02-05T01:07:02.639000Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# parameters \nSEED = 42\nMAX_LENGTH = 300\n\nOUTPUT_FOLDER = \".\"\nMODEL_ROOT = \"./models\"\n\nos.makedirs(MODEL_ROOT, exist_ok=True)\n\nn_epochs = 2\nper_device_train_batch_size = 3\nper_device_eval_batch_size = 2","metadata":{"_uuid":"49f24d57-124d-46af-8adc-376b1ccb9eff","_cell_guid":"159de41a-eeed-42e1-9808-0884a3296de6","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-05T01:07:04.634853Z","iopub.execute_input":"2025-02-05T01:07:04.635263Z","iopub.status.idle":"2025-02-05T01:07:04.640157Z","shell.execute_reply.started":"2025-02-05T01:07:04.635228Z","shell.execute_reply":"2025-02-05T01:07:04.638926Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Task(Enum):\n    TOKEN_CLASSIFICATION=\"token_classification\"\n    SEQUENCE_CLASSIFICATION = \"sequence_classification\"","metadata":{"_uuid":"f9ecd7a4-62a4-4f24-aaf6-e5c4ac7367cc","_cell_guid":"18485b9d-8e23-4629-ab0f-72de5a7246e9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-05T01:07:06.168541Z","iopub.execute_input":"2025-02-05T01:07:06.168868Z","iopub.status.idle":"2025-02-05T01:07:06.172604Z","shell.execute_reply.started":"2025-02-05T01:07:06.168840Z","shell.execute_reply":"2025-02-05T01:07:06.171780Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/commonlitreadabilityprize/train.csv')","metadata":{"_uuid":"20c6ec7f-96b2-41cb-b951-6ec54544ee6d","_cell_guid":"9be26ddd-5c63-4445-94ca-9b4fd72aada6","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-05T01:07:06.637682Z","iopub.execute_input":"2025-02-05T01:07:06.637969Z","iopub.status.idle":"2025-02-05T01:07:06.750113Z","shell.execute_reply.started":"2025-02-05T01:07:06.637947Z","shell.execute_reply":"2025-02-05T01:07:06.749452Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# setting the fold. \ndf['kfold'] = -1\n\nkf = KFold(n_splits=5, random_state=SEED, shuffle=True)\n\nfor f, (t_,v_) in enumerate(kf.split(X=np.arange(len(df)))):\n    df.loc[v_,'kfold'] = f","metadata":{"_uuid":"aef4734f-9929-4124-a20e-4740a552fd40","_cell_guid":"166b4d73-535c-40da-98c6-59cb40de2753","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-05T01:07:08.643588Z","iopub.execute_input":"2025-02-05T01:07:08.643932Z","iopub.status.idle":"2025-02-05T01:07:08.661061Z","shell.execute_reply.started":"2025-02-05T01:07:08.643905Z","shell.execute_reply":"2025-02-05T01:07:08.660423Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.kfold.value_counts()","metadata":{"_uuid":"d579bb00-20d9-4746-9e21-a0486d526063","_cell_guid":"7d5aaf5c-f6e5-4fb6-a0c9-feba5764bf59","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-05T01:07:46.538911Z","iopub.execute_input":"2025-02-05T01:07:46.539215Z","iopub.status.idle":"2025-02-05T01:07:46.551455Z","shell.execute_reply.started":"2025-02-05T01:07:46.539193Z","shell.execute_reply":"2025-02-05T01:07:46.550630Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# A utility to convert text to token ids and stack them \n\ndef generate_data(model_name='roberta-base'):\n    x_input_ids = []\n    x_masks = []\n    \n\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    # save the tokenizer to a file \n    with open(f'{OUTPUT_FOLDER}/{model_name}-tokenizer.pkl','wb') as f:\n        pickle.dump(tokenizer, f)\n\n    for excerpt in df.excerpt:\n        input_data = tokenizer(excerpt, add_special_tokens=True, \n                               return_tensors='pt', padding='max_length',\n                               max_length=MAX_LENGTH, truncation=True)\n                              \n        x_input_ids.append(input_data['input_ids'])\n        x_masks.append(input_data['attention_mask'])\n\n    x_input_ids = torch.cat(x_input_ids)\n    x_masks = torch.cat(x_masks)\n    y_target = torch.tensor(df.target.values, dtype=torch.float32)\n\n    return x_input_ids, x_masks, y_target","metadata":{"_uuid":"39096ddf-b58b-41f7-82c7-568e324c3d10","_cell_guid":"71e13ea6-1644-40ef-848e-4f2a4dbca0f5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-05T01:07:48.715346Z","iopub.execute_input":"2025-02-05T01:07:48.715629Z","iopub.status.idle":"2025-02-05T01:07:48.721004Z","shell.execute_reply.started":"2025-02-05T01:07:48.715608Z","shell.execute_reply":"2025-02-05T01:07:48.720063Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# define the dataset class \n\nclass CommonReadabilityDataset(Dataset):\n\n    def __init__(self, input_ids, masks, targets):\n        self.input_ids = input_ids\n        self.masks = masks\n        self.targets = targets\n\n    def __len__(self):\n        return len(self.input_ids)\n\n    def __getitem__(self,idx):\n        input_id = self.input_ids[idx]\n        mask = self.masks[idx]\n        target = self.targets[idx]\n\n        return (input_id, mask, target)","metadata":{"_uuid":"1e976471-2ba8-4413-bef6-0a9434384b72","_cell_guid":"90d7ab71-00c8-4d9c-8d97-692ed3245ba5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-05T01:07:50.169946Z","iopub.execute_input":"2025-02-05T01:07:50.170289Z","iopub.status.idle":"2025-02-05T01:07:50.175386Z","shell.execute_reply.started":"2025-02-05T01:07:50.170262Z","shell.execute_reply":"2025-02-05T01:07:50.174367Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train the model (includes head modification)\n\ndef get_model(model_name:str, num_targets, task:Task=Task.TOKEN_CLASSIFICATION):\n\n    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    config = AutoConfig.from_pretrained(model_name)\n\n    # define the model \n    if 'token' in task.value:\n        model = AutoModelForTokenClassification.from_pretrained(model_name)\n    if 'sequence' in task.value:\n        model = AutoModelForSequenceClassification.from_pretrained(model_name)\n\n    if hasattr(model, 'classifier'):\n        model.classifier = nn.Linear(model.classifier.in_features, num_targets)\n\n    return model, tokenizer, config","metadata":{"_uuid":"d16a9d6d-4398-4e4f-a05b-2748cf7f7b45","_cell_guid":"c430d0a9-c343-4a0e-b076-989e52a93f53","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-05T01:07:51.258384Z","iopub.execute_input":"2025-02-05T01:07:51.258688Z","iopub.status.idle":"2025-02-05T01:07:51.263629Z","shell.execute_reply.started":"2025-02-05T01:07:51.258663Z","shell.execute_reply":"2025-02-05T01:07:51.262717Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# define the attention block\nclass AttentionBlock(nn.Module):\n\n    def __init__(self, in_features, middle_features, out_features):\n        super(AttentionBlock, self).__init__()\n        self.in_features = in_features\n        self.middle_features = middle_features\n        self.out_features = out_features\n\n        self.W = nn.Linear(in_features, middle_features)\n        self.V = nn.Linear(middle_features, out_features)\n        \n    def forward(self, features):\n        att = torch.tanh(self.W(features)) #(bs, seq, middle_features)\n        scores = self.V(att) #(bs, seq, 1)\n\n        # convert the scores into probabilities\n        attention_weights = torch.softmax(scores, dim=1)\n        context_vector = attention_weights * features #(bs, seq, in_features)\n        context_vector = torch.sum(context_vector, dim=1) #(bs , in_features)\n\n        return context_vector","metadata":{"_uuid":"ce26a3c9-4f21-4916-afe4-c20b2cf9906d","_cell_guid":"ee82ab6a-23f6-41bd-94d9-7e73ce6bbdd2","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-05T01:07:52.814928Z","iopub.execute_input":"2025-02-05T01:07:52.815251Z","iopub.status.idle":"2025-02-05T01:07:52.820484Z","shell.execute_reply.started":"2025-02-05T01:07:52.815226Z","shell.execute_reply":"2025-02-05T01:07:52.819522Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MultHeadAttentionBlock(nn.Module):\n\n    def __init__(self,in_features, num_heads=8, dropout = 0.1):\n        super(MultHeadAttentionBlock,self).__init__()\n\n        self.num_heads = num_heads\n        self.head_dim = in_features // num_heads\n\n        self.norm = nn.LayerNorm(in_features)\n        \n        self.q_proj = nn.Linear(in_features, in_features)\n        self.k_proj = nn.Linear(in_features, in_features)\n        self.v_proj = nn.Linear(in_features, in_features)\n\n        self.proj = nn.Linear(in_features, in_features)\n\n        self.attn_drop = nn.Dropout(dropout)\n        self.out_drop = nn.Dropout(dropout)\n        \n\n    def forward(self, x, mask = None):\n        residual = x\n        x = self.norm(x)\n        \n        batch_size, seq_len, _ = x.shape\n\n        # reshaping \n        q = self.q_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim)\n        k = self.k_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim)\n        v = self.v_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim)\n\n        q = q.transpose(2,1)\n        k = k.transpose(2,1)\n        v = v.transpose(2,1)\n        \n        scores = torch.matmul(q, k.transpose(-2, -1))/math.sqrt(self.head_dim)\n\n        if mask is None:\n            scores = scores.masked_fill_(mask == 0, float('-inf'))\n        \n        attn = self.attn_drop(torch.softmax(scores, dim=-1))\n        # (b_s, num_heads,seq_len, head_dim)\n        out = torch.matmul(attn, v).transpose(1,2).contiguous().view(batch_size,seq_len,self.num_heads * self.head_dim)\n\n        return self.out_drop(self.proj(out)) + residual","metadata":{"_uuid":"17b28b13-8e70-44a7-8835-6aa9d8b9f501","_cell_guid":"d4608efe-f978-4155-92a9-9e6ad26bc6da","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-05T04:11:16.260461Z","iopub.execute_input":"2025-02-05T04:11:16.260768Z","iopub.status.idle":"2025-02-05T04:11:16.268711Z","shell.execute_reply.started":"2025-02-05T04:11:16.260745Z","shell.execute_reply":"2025-02-05T04:11:16.267736Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CounterFactual Reasoning Prediction\nclass CRPTokenModel(nn.Module):\n\n    def __init__(self, model_name: str, num_targets: int):\n        super(CRPTokenModel, self).__init__()\n\n        model, tokenizer, config = get_model(model_name= model_name, \n                                             num_targets = num_targets, \n                                             task = Task.TOKEN_CLASSIFICATION)\n\n        self.model = model\n        \n        in_features = model.classifier.in_features\n\n        self.model.classifier = nn.Identity()\n        self.att_blk = MultHeadAttentionBlock(in_features)\n        self.fc = nn.Linear(in_features, num_targets)\n\n    def forward(self, input_ids, attention_mask):\n\n        \n        output = self.model(input_ids=input_ids,\n                            attention_mask=attention_mask)\n        \n        context_features = self.att_blk(output['logits'], mask=attention_mask)\n        att_blk = torch.sum(context_features, dim=1)\n        return self.fc(att_blk)","metadata":{"_uuid":"d7cd902e-1476-48f9-83cd-4a59467f47c5","_cell_guid":"7031c480-9080-4e73-8b4a-84bb14a97db2","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-05T04:11:21.318768Z","iopub.execute_input":"2025-02-05T04:11:21.319092Z","iopub.status.idle":"2025-02-05T04:11:21.324659Z","shell.execute_reply.started":"2025-02-05T04:11:21.319065Z","shell.execute_reply":"2025-02-05T04:11:21.323798Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model, tokenizer, config = get_model(\"roberta-base\",num_targets=1,task=Task.TOKEN_CLASSIFICATION)","metadata":{"_uuid":"c62bcd7b-388b-496b-814c-d0272dc91512","_cell_guid":"35a1f1ae-50c1-49a7-9441-385e683c002c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-05T02:50:59.066631Z","iopub.execute_input":"2025-02-05T02:50:59.066957Z","iopub.status.idle":"2025-02-05T02:51:00.128294Z","shell.execute_reply.started":"2025-02-05T02:50:59.066930Z","shell.execute_reply":"2025-02-05T02:51:00.127616Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x_input_ids, x_masks, y_target = generate_data()\ndataset = CommonReadabilityDataset(input_ids = x_input_ids, masks=x_masks, targets = y_target)","metadata":{"_uuid":"51691a61-96d2-4993-ad94-7eb10dfd911f","_cell_guid":"9c11a527-bcbf-425a-ae31-1026a74eeced","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-05T01:08:37.604900Z","iopub.execute_input":"2025-02-05T01:08:37.605531Z","iopub.status.idle":"2025-02-05T01:08:40.349657Z","shell.execute_reply.started":"2025-02-05T01:08:37.605493Z","shell.execute_reply":"2025-02-05T01:08:40.348710Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir models","metadata":{"_uuid":"40e72321-5eb5-4c00-9d8a-fa1c6262c014","_cell_guid":"6bdaac4f-b274-4ddf-abb0-3435a0cdbc07","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-05T03:18:06.761499Z","iopub.execute_input":"2025-02-05T03:18:06.761828Z","iopub.status.idle":"2025-02-05T03:18:06.939726Z","shell.execute_reply.started":"2025-02-05T03:18:06.761799Z","shell.execute_reply":"2025-02-05T03:18:06.938507Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def one_step(input_id, attention_mask,y, model, loss_fn, optimizer, scheduler=None, device='cuda'):\n\n    input_id = input_id.to(device=device)\n    attention_mask = attention_mask.to(device=device)\n    y = y.to(device=device)\n    model.to(device=device)\n    optimizer.zero_grad()\n    \n    o = model(input_ids = input_id, attention_mask = attention_mask)\n    loss = loss_fn(o,y)\n    loss.backward()\n\n    with torch.no_grad():\n        l = loss.item()\n        r2 = r2_score(y.cpu().numpy(), o.cpu().numpy())\n        rmse = torch.sqrt(torch.mean(torch.square(o - y))).item()\n        mad = torch.mean(torch.abs(o - y)).item()\n    \n    optimizer.step()\n    return l, r2, rmse, mad","metadata":{"_uuid":"de3c109b-1eb1-4c61-a338-fabde3f8cb1c","_cell_guid":"996600d4-a284-48e8-a1a0-7a6a83a60bc6","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-05T01:33:23.650431Z","iopub.execute_input":"2025-02-05T01:33:23.650769Z","iopub.status.idle":"2025-02-05T01:33:23.656278Z","shell.execute_reply.started":"2025-02-05T01:33:23.650738Z","shell.execute_reply":"2025-02-05T01:33:23.655441Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@torch.no_grad()\ndef evaluate(model, valid_dl, criterion, device):\n    model.eval()\n    progress_bar = tqdm(valid_dl, leave=False)\n    predicted_output, actual_target = [],[]\n    for (input_id, mask, target) in progress_bar:\n\n        input_id = input_id.to(device=device)\n        mask = mask.to(device=device)\n        target = target.to(device=device)\n        model.to(device=device)\n        \n        o = model(input_ids = input_id, attention_mask = mask)\n        predicted_output.append(o)\n        actual_target.append(target)\n\n    predicted_output = torch.cat(predicted_output)\n    actual_target = torch.cat(actual_target)\n\n    rmse = torch.sqrt(torch.mean(torch.square(predicted_output - actual_target))).item()\n    mean_absolute_deviation = torch.mean(predicted_output - actual_target).item()\n    val_loss = criterion(predicted_output, actual_target).item()\n    r2 = r2_score(actual_target.cpu().numpy(), predicted_output.cpu().numpy())\n\n    return val_loss, r2_score, rmse, mean_absolute_deviation","metadata":{"_uuid":"4cc712c5-1291-411f-b833-744616f08760","_cell_guid":"d5afde26-db7a-47c4-8992-c412c36e7cc2","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-05T01:33:24.836095Z","iopub.execute_input":"2025-02-05T01:33:24.836463Z","iopub.status.idle":"2025-02-05T01:33:24.842423Z","shell.execute_reply.started":"2025-02-05T01:33:24.836425Z","shell.execute_reply":"2025-02-05T01:33:24.841531Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def one_epoch(model, criterion, optimizer, scheduler, train_dl, valid_dl, device='cuda'):\n\n    model.train()\n    loss,r2,root_mean_square, mean_absolute_deviation, iteration = 0,0,0,0,0\n    progress_bar = tqdm(train_dl, leave=False)\n    \n    \n    for (input_id, mask, target) in progress_bar:\n        _loss,_r2,_root_mean_square, _mean_absolute_deviation = one_step(input_id,mask,target,model, criterion,optimizer, device=device)\n        \n        loss += _loss\n        r2 += _r2\n        root_mean_square += _root_mean_square\n        mean_absolute_deviation += _mean_absolute_deviation \n        \n        iteration += 1\n\n        progress_bar.set_postfix(\n            loss='{:.3f}'.format(loss/iteration),\n            r2='{:.3f}'.format(r2/iteration),\n            root_mean_square='{:.3f}'.format(root_mean_square/iteration),\n            mean_absolute_deviation='{:.3f}'.format(mean_absolute_deviation/iteration)\n        )\n\n        scheduler.step()\n\n    loss /= iteration\n    r2 /= iteration\n    root_mean_square /= iteration\n    mean_absolute_deviation /= iteration\n    val_loss, r2_val_score, val_rmse, val_mean_absolute_deviation = evaluate(model, valid_dl, criterion, device)\n\n    return (loss, val_loss),(r2, r2_val_score),(mean_absolute_deviation, val_mean_absolute_deviation),(root_mean_square,val_rmse)","metadata":{"_uuid":"4748383c-c27c-4c01-9823-c06ff520dd60","_cell_guid":"8d922330-76db-4862-8ae4-e117d90d5124","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-05T01:33:36.364193Z","iopub.execute_input":"2025-02-05T01:33:36.364496Z","iopub.status.idle":"2025-02-05T01:33:36.370437Z","shell.execute_reply.started":"2025-02-05T01:33:36.364473Z","shell.execute_reply":"2025-02-05T01:33:36.369539Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SaveModelConfiguration:\n\n    def __init__(self,name, metric, mode='min', top_k=2):\n        self.logs = []\n        self.metric = metric\n        self.mode = mode\n        self.top_metrics = []\n        self.top_k = top_k\n        self.name = name\n        self.model_root_path = Path(MODEL_ROOT)\n        self.top_models = []\n        self.logs = []\n\n    def log(self, model, metrics):\n        metric = metrics[self.metric]\n        rank = self.get_rank(metric)\n\n        if len(self.top_metrics) > self.top_k:\n            self.top_metrics.pop()\n        self.top_metrics.insert(rank + 1, metric)\n\n        self.logs.append(metrics)\n        self.save(model, metric, metrics['epoch'], rank)\n    \n    def save(self, model, metric, epoch, rank):\n        timestamp = time.strftime('%Y%m%d%H%M%S')\n        \n        # create filename format: name_epoch_01_loss_0.45_timestamp.pth\n        name = \"{}_epoch_{:02d}_{}_{:.04f}_{}\".format(\n            self.name,\n            epoch,\n            self.metric,\n            metric,\n            timestamp\n        ) \n\n        # remove unwanted characters \n        name = re.sub(r'[^\\w_\\-\\.]','',name) + '.pth'\n        self.top_models.insert(rank+1, name)\n\n        if len(self.top_models) > self.top_k:\n            last_model_name = self.top_models[-1]\n            old_model = self.model_root_path.joinpath(last_model_name)\n\n            if old_model:\n                old_model.unlink()\n        \n        model_path = self.model_root_path.joinpath(name)\n        torch.save(model.state_dict(), model_path)\n\n        \n    def get_rank(self, val):\n\n        if self.mode == 'min':\n            for index, metric_val in enumerate(self.top_metrics):\n                if val <= metric_val:\n                    return index - 1\n\n        if self.mode == 'max':\n            self.top_metrics = sorted(self.top_metrics, reverse=True)\n            for index, metric_val in enumerate(self.top_metrics):\n                if val >= metric_val:\n                    return index - 1\n                    \n        return len(self.top_metrics)  - 1    \n\n    def write_to_json(self):\n        name = \"{}_logs\".format(self.name)\n        name = re.sub(r\"[^\\w_\\-\\.]\", \"\", name) + \".json\"\n        path = self.model_root_path.joinpath(name)\n        \n        with path.open('w') as f:\n            json.dump(self.logs, indent=2)","metadata":{"_uuid":"2278cf2a-bdf8-4008-8051-c6cfefa2c392","_cell_guid":"bd17e3de-1df3-408c-a22f-35c43604a507","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-05T01:33:37.569305Z","iopub.execute_input":"2025-02-05T01:33:37.569585Z","iopub.status.idle":"2025-02-05T01:33:37.578619Z","shell.execute_reply.started":"2025-02-05T01:33:37.569564Z","shell.execute_reply":"2025-02-05T01:33:37.577826Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def one_fold(model_name, train_set, valid_set, num_targets=1, save=True, device='cuda'):\n    # collect information from epoch\n    # (loss, val_loss),(r2, r2_val_score),(mean_absolute_deviation, val_mad),(root_mean_square,val_rmse)\n    model_saver = SaveModelConfiguration(name='roberta-base', metric='loss')\n\n    model = CRPTokenModel(model_name, num_targets = num_targets)\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=1e-5, T_max=n_epochs)\n\n    train_input_ids, train_masks, train_target = x_input_ids[train_set], x_masks[train_set], y_target[train_set]\n    train_dataset = CommonReadabilityDataset(input_ids = train_input_ids, masks=train_masks, targets = train_target)\n\n    train_dl = DataLoader(train_dataset, pin_memory=True, shuffle=True, batch_size=per_device_train_batch_size, num_workers=2)\n\n    valid_input_ids, valid_masks, valid_target = x_input_ids[train_set], x_masks[train_set], y_target[train_set]\n    valid_dataset = CommonReadabilityDataset(input_ids = train_input_ids, masks=train_masks, targets = train_target)\n\n    valid_dl = DataLoader(valid_dataset, pin_memory=True, shuffle=False, batch_size=per_device_eval_batch_size, num_workers=2)\n\n    progress_bar = tqdm(range(n_epochs), leave=False)\n    criterion = nn.MSELoss()\n    \n    for epoch in progress_bar:\n        progress_bar.set_description(f'Epoch {epoch:02d}')\n\n        model.train()\n        (loss, val_loss),(r2, r2_val_score),(mean_absolute_deviation, val_mean_absolute_deviation),(root_mean_square,val_rmse) = one_epoch(\n            model, criterion, optimizer, scheduler, train_dl, valid_dl)\n        \n        progress_bar.set_postfix(\n            loss='({:.3f},{:.3f})'.format(loss, val_loss),\n            rmse='({:.3f},{:.3f})'.format(root_mean_square, val_rmse),\n            mad='({:.3f},{:.3f})'.format(mean_absolute_deviation, val_mean_absolute_deviation)\n        )\n\n        if save:\n            progress_metrics = {\n                'epoch':epoch,\n                'rmse': -root_mean_square,'mad': mean_absolute_deviation, 'r2':r2, 'loss':loss,\n                'val_rmse':val_rmse, 'val_mad':val_mean_absolute_deviation, 'r2_val_score':r2_val_score,'val_loss':val_loss\n            }\n            model_saver.log(model=model, metrics=progress_metrics)","metadata":{"_uuid":"1e6f7036-401b-467e-9c0a-9c05510c7f59","_cell_guid":"63c306db-9b63-43f3-9b24-8f08c534ea07","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-05T01:33:38.916523Z","iopub.execute_input":"2025-02-05T01:33:38.916816Z","iopub.status.idle":"2025-02-05T01:33:38.924651Z","shell.execute_reply.started":"2025-02-05T01:33:38.916794Z","shell.execute_reply":"2025-02-05T01:33:38.923583Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train(model_name, num_targets=1, seed=42):\n    gc.collect()\n    torch.cuda.empty_cache()\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    \n    fold_bar = tqdm(df.reset_index(drop=True).reset_index().groupby('kfold').index.apply(list).items(),total=df.kfold.max() + 1)\n    \n    # seed everything \n    seed = seed_everything(seed=132)\n    \n    for fold, valid_set in fold_bar:\n        fold_bar.set_description(f'FOLD {fold} SEED {seed}')\n    \n        train_set = np.setdiff1d(df.index, valid_set)\n        one_fold(model_name, train_set, valid_set, num_targets=num_targets, save=True, device=device)\n    \n        gc.collect()\n        torch.cuda.empty_cache()","metadata":{"_uuid":"589f5ee1-1515-43fc-b5a5-1c3525d86c37","_cell_guid":"abe9ce93-52f7-4434-9f79-f681cbf48f0a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-05T04:11:36.944325Z","iopub.execute_input":"2025-02-05T04:11:36.944723Z","iopub.status.idle":"2025-02-05T04:11:36.952047Z","shell.execute_reply.started":"2025-02-05T04:11:36.944691Z","shell.execute_reply":"2025-02-05T04:11:36.951034Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train('roberta-base', num_targets=1, seed=42)","metadata":{"_uuid":"13256d96-3aaf-40ad-a505-bfe53c9df117","_cell_guid":"87a80b7e-6564-4307-8048-c9348baa7ff4","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-05T04:11:38.643481Z","iopub.execute_input":"2025-02-05T04:11:38.643803Z","iopub.status.idle":"2025-02-05T04:37:14.635020Z","shell.execute_reply.started":"2025-02-05T04:11:38.643769Z","shell.execute_reply":"2025-02-05T04:37:14.633881Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"d5134f8a-e43e-4497-bbaf-1e3e3a3128a1","_cell_guid":"b4d4b1bf-7d83-4ee8-83ec-18d44bed0709","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}